#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Tests de regresi√≥n para m√©tricas cr√≠ticas de HotBoat
Estos tests calculan m√©tricas financieras clave y las comparan con un baseline.
USAN DATOS EST√ÅTICOS desde tests/test_data/ para garantizar consistencia.
"""

import pandas as pd
import os
import sys
import json
from datetime import datetime

# Agregar el directorio padre al path para poder importar m√≥dulos
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Importar el cargador de datos de test
from test_data_loader import cargar_datos_test

class TestMetricasRegression:
    """Tests de regresi√≥n para m√©tricas cr√≠ticas del negocio"""
    
    def __init__(self):
        """Configuraci√≥n inicial"""
        self.baseline_file = os.path.join(os.path.dirname(__file__), 'baselines', 'metricas_baseline_test.json')
        self.tolerance = 0.01  # 1% de tolerancia
        
        # Crear directorio de baselines si no existe
        baseline_dir = os.path.dirname(self.baseline_file)
        if not os.path.exists(baseline_dir):
            os.makedirs(baseline_dir)
    
    def calcular_metricas_test(self):
        """Calcula m√©tricas usando datos est√°ticos de test"""
        print("üìä Calculando m√©tricas con datos de test...")
        
        datos = cargar_datos_test()
        metricas = {}
        
        try:
            # === INGRESOS ===
            if not datos['ingresos'].empty and 'monto' in datos['ingresos'].columns:
                metricas['total_ingresos_test'] = float(datos['ingresos']['monto'].sum())
                metricas['promedio_ingreso_test'] = float(datos['ingresos']['monto'].mean())
                metricas['num_transacciones_ingresos'] = len(datos['ingresos'])
            else:
                metricas['total_ingresos_test'] = 0.0
                metricas['promedio_ingreso_test'] = 0.0
                metricas['num_transacciones_ingresos'] = 0
            
            # === COSTOS OPERATIVOS ===
            if not datos['costos_operativos'].empty and 'monto' in datos['costos_operativos'].columns:
                metricas['total_costos_operativos_test'] = float(datos['costos_operativos']['monto'].sum())
                metricas['promedio_costo_operativo'] = float(datos['costos_operativos']['monto'].mean())
            else:
                metricas['total_costos_operativos_test'] = 0.0
                metricas['promedio_costo_operativo'] = 0.0
            
            # === GASTOS MARKETING ===
            if not datos['gastos_marketing'].empty and 'monto' in datos['gastos_marketing'].columns:
                metricas['total_gastos_marketing_test'] = float(datos['gastos_marketing']['monto'].sum())
                metricas['promedio_gasto_marketing'] = float(datos['gastos_marketing']['monto'].mean())
            else:
                metricas['total_gastos_marketing_test'] = 0.0
                metricas['promedio_gasto_marketing'] = 0.0
            
            # === COSTOS FIJOS ===
            if not datos['costos_fijos'].empty and 'monto_mensual' in datos['costos_fijos'].columns:
                metricas['total_costos_fijos_mensual'] = float(datos['costos_fijos']['monto_mensual'].sum())
                metricas['num_conceptos_costos_fijos'] = len(datos['costos_fijos'])
            else:
                metricas['total_costos_fijos_mensual'] = 0.0
                metricas['num_conceptos_costos_fijos'] = 0
            
            # === M√âTRICAS CALCULADAS ===
            if metricas['total_ingresos_test'] > 0:
                # Utilidad bruta
                metricas['utilidad_bruta_test'] = metricas['total_ingresos_test'] - metricas['total_costos_operativos_test']
                
                # Margen bruto
                metricas['margen_bruto_test'] = (metricas['utilidad_bruta_test'] / metricas['total_ingresos_test']) * 100
                
                # ROI Marketing (si hay gastos de marketing)
                if metricas['total_gastos_marketing_test'] > 0:
                    metricas['roi_marketing_test'] = (metricas['total_ingresos_test'] / metricas['total_gastos_marketing_test']) * 100
                else:
                    metricas['roi_marketing_test'] = 0.0
                
                # Costo por transacci√≥n
                if metricas['num_transacciones_ingresos'] > 0:
                    metricas['costo_por_transaccion'] = metricas['total_costos_operativos_test'] / metricas['num_transacciones_ingresos']
                else:
                    metricas['costo_por_transaccion'] = 0.0
            else:
                metricas['utilidad_bruta_test'] = 0.0
                metricas['margen_bruto_test'] = 0.0
                metricas['roi_marketing_test'] = 0.0
                metricas['costo_por_transaccion'] = 0.0
            
            # Timestamp del c√°lculo
            metricas['fecha_calculo'] = datetime.now().isoformat()
            metricas['tipo_datos'] = 'test_estaticos'
            
            print(f"‚úÖ M√©tricas calculadas: {len(metricas)} m√©tricas")
            return metricas
            
        except Exception as e:
            print(f"‚ùå Error al calcular m√©tricas: {e}")
            raise
    
    def guardar_baseline(self, metricas):
        """Guarda las m√©tricas como baseline"""
        try:
            with open(self.baseline_file, 'w', encoding='utf-8') as f:
                json.dump(metricas, f, indent=2, ensure_ascii=False)
            print(f"‚úÖ Baseline guardado en: {self.baseline_file}")
        except Exception as e:
            print(f"‚ùå Error al guardar baseline: {e}")
            raise
    
    def cargar_baseline(self):
        """Carga el baseline guardado"""
        try:
            if os.path.exists(self.baseline_file):
                with open(self.baseline_file, 'r', encoding='utf-8') as f:
                    baseline = json.load(f)
                print(f"‚úÖ Baseline cargado desde: {self.baseline_file}")
                return baseline
            else:
                print("‚ÑπÔ∏è No existe baseline previo")
                return None
        except Exception as e:
            print(f"‚ùå Error al cargar baseline: {e}")
            return None
    
    def comparar_con_baseline(self, metricas_actuales, baseline):
        """Compara m√©tricas actuales con baseline"""
        cambios_significativos = []
        
        print("üîç Comparando con baseline...")
        
        for key, valor_actual in metricas_actuales.items():
            if key in ['fecha_calculo', 'tipo_datos']:
                continue
                
            if key in baseline and isinstance(valor_actual, (int, float)):
                valor_baseline = baseline[key]
                
                if valor_baseline != 0:
                    cambio_porcentual = ((valor_actual - valor_baseline) / valor_baseline) * 100
                    
                    if abs(cambio_porcentual) > (self.tolerance * 100):
                        cambios_significativos.append({
                            'metrica': key,
                            'baseline': valor_baseline,
                            'actual': valor_actual,
                            'cambio_porcentual': cambio_porcentual
                        })
                        print(f"‚ö†Ô∏è Cambio significativo en {key}: {cambio_porcentual:.2f}%")
                    else:
                        print(f"‚úÖ {key}: cambio {cambio_porcentual:.2f}% (dentro de tolerancia)")
                elif valor_actual != 0:
                    # Valor baseline era 0 pero ahora no
                    cambios_significativos.append({
                        'metrica': key,
                        'baseline': valor_baseline,
                        'actual': valor_actual,
                        'cambio_porcentual': float('inf')
                    })
                    print(f"‚ö†Ô∏è Nueva m√©trica con valor: {key}")
        
        return cambios_significativos
    
    def test_calculo_metricas(self):
        """Test que verifica que se puedan calcular m√©tricas"""
        metricas = self.calcular_metricas_test()
        
        # Verificar que se calcularon m√©tricas m√≠nimas
        assert len(metricas) > 5, f"Se esperaban al menos 6 m√©tricas, se calcularon {len(metricas)}"
        
        # Verificar m√©tricas cr√≠ticas
        metricas_criticas = ['total_ingresos_test', 'total_costos_operativos_test', 'utilidad_bruta_test']
        for metrica in metricas_criticas:
            assert metrica in metricas, f"M√©trica cr√≠tica faltante: {metrica}"
        
        print("‚úÖ Test de c√°lculo de m√©tricas pas√≥")
        return metricas
    
    def test_regression_vs_baseline(self):
        """Test de regresi√≥n principal"""
        # Calcular m√©tricas actuales
        metricas_actuales = self.calcular_metricas_test()
        
        # Cargar baseline
        baseline = self.cargar_baseline()
        
        if baseline is None:
            # Crear baseline inicial
            print("üîß Creando baseline inicial...")
            self.guardar_baseline(metricas_actuales)
            print("‚úÖ Baseline inicial creado exitosamente")
            return metricas_actuales
        
        # Comparar con baseline
        cambios = self.comparar_con_baseline(metricas_actuales, baseline)
        
        if cambios:
            print(f"\n‚ö†Ô∏è DETECTADOS {len(cambios)} CAMBIOS SIGNIFICATIVOS:")
            for cambio in cambios:
                print(f"   {cambio['metrica']}: {cambio['baseline']} ‚Üí {cambio['actual']} ({cambio['cambio_porcentual']:.2f}%)")
            
            # Decidir si fallar el test o actualizar baseline
            respuesta = input("\n¬øActualizar baseline con nuevos valores? (y/N): ").lower()
            if respuesta == 'y':
                self.guardar_baseline(metricas_actuales)
                print("‚úÖ Baseline actualizado")
            else:
                raise AssertionError(f"Test de regresi√≥n fall√≥: {len(cambios)} cambios significativos")
        else:
            print("‚úÖ No hay cambios significativos detectados")
        
        return metricas_actuales
    
    def test_metricas_sanity_check(self):
        """Test de sanidad para verificar que las m√©tricas tienen sentido"""
        metricas = self.calcular_metricas_test()
        
        # Verificar que los valores son razonables
        if metricas['total_ingresos_test'] > 0:
            assert metricas['utilidad_bruta_test'] <= metricas['total_ingresos_test'], "Utilidad bruta no puede ser mayor que ingresos"
            assert metricas['margen_bruto_test'] <= 100, "Margen bruto no puede ser mayor que 100%"
        
        if metricas['total_costos_fijos_mensual'] > 0:
            assert metricas['num_conceptos_costos_fijos'] == 6, f"Se esperaban 6 conceptos de costos fijos, se encontraron {metricas['num_conceptos_costos_fijos']}"
        
        print("‚úÖ Test de sanidad de m√©tricas pas√≥")
        return metricas

def run_tests():
    """Ejecuta todos los tests de regresi√≥n"""
    test_instance = TestMetricasRegression()
    
    print("üß™ EJECUTANDO TESTS DE REGRESI√ìN CON DATOS DE TEST")
    print("=" * 65)
    
    tests = [
        test_instance.test_calculo_metricas,
        test_instance.test_regression_vs_baseline,
        test_instance.test_metricas_sanity_check
    ]
    
    passed = 0
    failed = 0
    
    for test in tests:
        try:
            print(f"\nüîç Ejecutando: {test.__name__}")
            result = test()
            passed += 1
            print(f"‚úÖ {test.__name__} - PAS√ì")
        except Exception as e:
            print(f"‚ùå {test.__name__} fall√≥: {e}")
            failed += 1
    
    print(f"\nüìä Resumen: {passed} passed, {failed} failed")
    
    if failed == 0:
        print("üéâ TODOS LOS TESTS DE REGRESI√ìN PASARON")
        return True
    else:
        print(f"‚ùå {failed} TESTS FALLARON")
        return False

if __name__ == "__main__":
    success = run_tests()
    sys.exit(0 if success else 1) 